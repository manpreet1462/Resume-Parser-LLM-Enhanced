# ============================================
# Document Processing with AI - Configuration
# ============================================

# PINECONE VECTOR DATABASE CONFIGURATION
# Get your free API key at: https://pinecone.io
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=us-east-1
PINECONE_INDEX_NAME=ai-documents

# OLLAMA LOCAL AI CONFIGURATION
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# APPLICATION SETTINGS
APP_NAME=AI Document Assistant
DEBUG_MODE=false

# ============================================
# SETUP INSTRUCTIONS:
# 1. Copy this file to .env: cp .env.example .env
# 2. Replace 'your_pinecone_api_key_here' with your actual API key
# 3. Make sure Ollama is running: ollama serve
# 4. Pull the required model: ollama pull llama3.2:3b
# 5. Run the app: streamlit run app.py
# ============================================